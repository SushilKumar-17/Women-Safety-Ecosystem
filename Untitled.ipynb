{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d71630-f3f1-4085-be93-1288eda1e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ybadr\\anaconda3\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ybadr\\anaconda3\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTForImageClassification.\n",
      "\n",
      "All the weights of TFViTForImageClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alert: Fighting detected with score: 0.9860636591911316\n",
      "Alert: Fighting detected with score: 0.9834449291229248\n",
      "Alert: Fighting detected with score: 0.9798523187637329\n",
      "Alert: Fighting detected with score: 0.9755856990814209\n",
      "Alert: Fighting detected with score: 0.9729750752449036\n",
      "Alert: Fighting detected with score: 0.9710755348205566\n",
      "Alert: Fighting detected with score: 0.9648410677909851\n",
      "Alert: Fighting detected with score: 0.9816803932189941\n",
      "Alert: Fighting detected with score: 0.9791573882102966\n",
      "Alert: Fighting detected with score: 0.9765579104423523\n",
      "Alert: Fighting detected with score: 0.974109947681427\n",
      "Alert: Fighting detected with score: 0.9690942764282227\n",
      "Alert: Fighting detected with score: 0.9802656769752502\n",
      "Alert: Fighting detected with score: 0.970061719417572\n",
      "Alert: Fighting detected with score: 0.973352313041687\n",
      "Alert: Fighting detected with score: 0.9857282042503357\n",
      "Alert: Fighting detected with score: 0.9877805709838867\n",
      "Alert: Fighting detected with score: 0.9866557121276855\n",
      "Alert: Fighting detected with score: 0.9858126640319824\n",
      "Alert: Fighting detected with score: 0.9660704731941223\n",
      "Alert: Fighting detected with score: 0.9761216640472412\n",
      "Alert: Fighting detected with score: 0.9774594902992249\n",
      "Alert: Fighting detected with score: 0.9854334592819214\n",
      "Alert: Fighting detected with score: 0.9840896129608154\n",
      "Alert: Fighting detected with score: 0.9762412905693054\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the classification pipeline\n",
    "pipe = pipeline(\"image-classification\", model=\"rvv-karma/Human-Action-Recognition-VIT-Base-patch16-224\", framework=\"tf\")\n",
    "\n",
    "# Load the video\n",
    "video_path = r\"C:\\Users\\ybadr\\SIH Rough\\SIH VIDS\\CCTV footages lay bare the horrors of chain snatching robbers in Chennai.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize a counter for detected instances\n",
    "count = 0\n",
    "\n",
    "# Iterate through video frames\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the RGB frame to a PIL Image\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "\n",
    "    # Predict the action in the frame\n",
    "    result = pipe(pil_image)\n",
    "\n",
    "    # Check if 'Fighting' score is above 0.8 and print an alert\n",
    "    for item in result:\n",
    "        if item['label'] == 'Fighting' and item['score'] > 0.92:\n",
    "            print(\"Alert: Fighting detected with score:\", item['score'])\n",
    "            count += 1\n",
    "            break  # Exit the loop after detecting fighting\n",
    "\n",
    "    # Break the loop if 15 instances have been detected\n",
    "    if count == 25:\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516e5aef-8e14-4d39-86d8-969726c142a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
